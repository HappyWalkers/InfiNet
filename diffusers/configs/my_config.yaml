pretrained_model_path: "./models/model_scope_diffusers/" #https://huggingface.co/damo-vilab/text-to-video-ms-1.7b/tree/main
output_dir: "./outputs"
train_text_encoder: False

train_data:
  json_path: "./json/train.json"
  preprocessed: True
  n_sample_frames: 8
  width: 128      
  height: 64
  sample_start_idx: 0
  sample_frame_rate: 15
  use_random_start_idx: False
  vid_data_key: "video_path"

  single_video_path: ""
  single_video_prompt: ""

  infinet_source_path: "video"

validation_data:
  prompt: "The video starts with digits 8 and 5. The 8 moves left and upwards, while the 5 moves right and alternates between upwards and downwards, all while maintaining their size and rotation. This pattern continues throughout the video."
  sample_preview: True
  num_frames: 16
  width: 128
  height: 64
  num_inference_steps: 50
  guidance_scale: 9

learning_rate: 5e-6 
adam_weight_decay: 1e-2
train_batch_size: 1
max_train_steps: 50000
checkpointing_steps: 1000
validation_steps: 500
trainable_modules:
  - "attn1.to_out"
  - "attn2.to_out"
  - "infinet"
seed: 64
mixed_precision: "fp16"
use_8bit_adam: False # This seems to be incompatible at the moment. 
gradient_checkpointing: False
enable_xformers_memory_efficient_attention: False

# Use scaled dot product attention (Only available with >= Torch 2.0)
enable_torch_2_attn: True
